# -*- coding: utf-8 -*-
"""Checkpoint1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17HT77FSa-zP2Yiz_knW967GmTzVFmT2-
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from torchvision import transforms

train_df = pd.read_csv("train.csv")
test_df = pd.read_csv("test.csv")
# Keep only the pixel columns
test_df = test_df.loc[:, test_df.columns.str.startswith("pixel")]

transform = transforms.Compose([
    transforms.Lambda(lambda x: x / 255.0),  # from [0,255] to [0,1]
    transforms.Normalize((0.5,), (0.5,))
])



X = train_df.drop("label", axis=1)
y = train_df["label"]

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)

train_dataset = FashionDataset(X_train, y_train)
val_dataset = FashionDataset(X_val, y_val)
test_dataset = FashionDataset(test_df)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64)
test_loader = DataLoader(test_dataset, batch_size=64)

class FashionDataset(Dataset):
    def __init__(self, data, labels=None, transform=None):
        self.images = data.values.astype(np.float32).reshape(-1, 28, 28)
        self.labels = labels.values.astype(np.longlong) if labels is not None else None
        self.transform= self.transform(img)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img = self.images[idx]
        img = np.expand_dims(img, 0)  # Make it (1, 28, 28)
        img = torch.tensor(img)
        if self.transform:
            img = self.transform(img)
        if self.labels is not None:
            return img, self.labels[idx]
        print(img.shape)  # should be torch.Size([1, 28, 28])

        return img

class LeNetLike(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(1, 6, 5),  # 28x28 -> 24x24
            nn.Tanh(),
            nn.AvgPool2d(2),     # 24x24 -> 12x12
            nn.Conv2d(6, 16, 5), # 12x12 -> 8x8
            nn.Tanh(),
            nn.AvgPool2d(2),     # 8x8 -> 4x4
            nn.Flatten(),
            nn.Linear(16*4*4, 120),
            nn.Tanh(),
            nn.Linear(120, 84),
            nn.Tanh(),
            nn.Linear(84, 10)
        )

    def forward(self, x):
        return self.model(x)

model = LeNetLike().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

for epoch in range(20):
    model.train()
    total_loss = 0
    correct = 0
    total = 0

    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    acc = 100 * correct / total
    print(f"Epoch {epoch+1} | Loss: {total_loss:.3f} | Train Accuracy: {acc:.2f}%")

model.eval()
val_correct = 0
val_total = 0

with torch.no_grad():
    for imgs, labels in val_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        outputs = model(imgs)
        _, preds = torch.max(outputs, 1)
        val_correct += (preds == labels).sum().item()
        val_total += labels.size(0)

print(f"Validation Accuracy: {100 * val_correct / val_total:.2f}%")

model.eval()
predictions = []

with torch.no_grad():
    for imgs in test_loader:
        imgs = imgs.to(device)
        outputs = model(imgs)
        _, preds = torch.max(outputs, 1)
        predictions.extend(preds.cpu().numpy())

submission = pd.DataFrame({
    "id": np.arange(0, len(predictions)),
    "label": predictions
})

submission.to_csv("submission.csv", index=False)

